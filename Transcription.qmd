---
title: "SpellCheck_Transcription"
format: html
---


```{r, include=F}
# Load necessary libraries
required_packages <- c("tuneR", "seewave", "audio", "speech", "tidyverse", "text", "reticulate", "av", "googleLanguageR", "tidytext", "dplyr", "udpipe", "topicmodels", "tm", "ggplot2", "sqldf", "textrank", "hunspell", "viridis", "reshape2")

# Check for missing packages and install them if necessary
missing_packages <- required_packages[!(required_packages %in% installed.packages()[,"Package"])]
if(length(missing_packages)) install.packages(missing_packages)

# Load all required packages
lapply(required_packages, library, character.only = TRUE)
```



```{r, include=F}
# Create a new virtual environment
virtualenv_create("whisper_env")
use_virtualenv("whisper_env", required = TRUE)


# Install specific version of numpy and other Python packages using pip
py_install("pip", "setuptools", "wheel", method = "virtualenv", envname = "whisper_env")
py_install("numpy==1.26.4", envname = "whisper_env")
py_install("pydub", "SpeechRecognition", "librosa", method = "virtualenv", envname = "whisper_env")
py_install("git+https://github.com/openai/whisper.git", method = "virtualenv", envname = "whisper_env")

# Verify numpy version
py_run_string("import numpy; print(numpy.__version__)")
```

```{r}
# Define file paths (use absolute paths)
mp3_file <- "C:/Users/16503/Documents/RSC/Practice/Audio_Transcription/audio-sample-4.mp3"
wave_file <- "C:/Users/16503/Documents/RSC/Practice/Audio_Transcription/audio-sample-4.wav"
```

```{r, include=F}
# Convert MP3 to WAV
av::av_audio_convert(mp3_file, wave_file)

# Load the necessary Python modules
reticulate::import("whisper")
reticulate::import("pydub")
reticulate::import("os")
reticulate::import("numpy")
reticulate::import("librosa")

# Define Python functions in R
convert_mp3_to_wav <- function(mp3_path, wav_path) {
  pydub <- import("pydub")
  audio <- pydub$AudioSegment$from_mp3(mp3_path)
  audio$export(wav_path, format="wav")
}

transcribe_audio <- function(wav_path) {
  whisper <- import("whisper")
  model <- whisper$load_model("base")
  result <- model$transcribe(wav_path)
  return(result)
}

analyze_tonality <- function(wav_path) {
  librosa <- import("librosa")
  
  # Load the audio file
  audio_data <- librosa$load(wav_path)
  y <- audio_data[[1]]
  sr <- audio_data[[2]]
  
  # Extract tonal features
  chroma <- librosa$feature$chroma_stft(y = y, sr = sr)
  tonnetz <- librosa$feature$tonnetz(y = librosa$effects$harmonic(y), sr = sr)
  harmony <- librosa$effects$harmonic(y)
  percussive <- librosa$effects$percussive(y)
  
  # Convert features to data frames for plotting
  chroma_df <- as.data.frame(t(chroma))
  tonnetz_df <- as.data.frame(t(tonnetz))
  harmony_df <- data.frame(time = seq_along(harmony), amplitude = harmony)
  percussive_df <- data.frame(time = seq_along(percussive), amplitude = percussive)
  
  return(list(chroma = chroma_df, tonnetz = tonnetz_df, harmony = harmony_df, percussive = percussive_df))
}


# Convert MP3 to WAV
convert_mp3_to_wav(mp3_file, wave_file)
```

```{r, include=F}
# Transcribe Audio
transcription <- transcribe_audio(wave_file)
```

```{r}
transcription_text <- transcription$text
```


```{r}
# Analyze Tonality
tonal_features <- analyze_tonality(wave_file)
# Define the file path
file_path <- "C:/Users/16503/Documents/RSC/Practice/Audio_Transcription/tonal_features.rds"

# Save the tonal_features object to the specified file path
saveRDS(tonal_features, file = file_path)

```

```{r}
#print(transcription)
#str(transcription)
```

```{r}
correct_spelling <- function(text, exclude_words = c("Th", "t", "h", "the", "nth", "tho", "thy", "eh", "ts", "sh", "ti", "ta", "ah", "tn", "10th", "February", "2010")) {
  words <- unlist(strsplit(text, "\\s+"))
  words_to_check <- setdiff(words, exclude_words)
  misspelled <- hunspell::hunspell(words_to_check)
  suggestions <- lapply(misspelled, hunspell::hunspell_suggest)
  
  corrections <- sapply(suggestions, function(x) if (length(x) > 0) x[[1]] else NA, USE.NAMES = FALSE)
  
  # Map corrections back to the original list of words
  corrected_text <- sapply(words, function(word) {
    if (word %in% words_to_check) {
      corrected_word <- corrections[which(words_to_check == word)]
      if (!is.na(corrected_word)) {
        return(corrected_word)
      }
    }
    return(word)
  })
  
  return(paste(corrected_text, collapse = " "))
}

# Apply spell-check and correction
corrected_transcription_text <- correct_spelling(transcription_text)
transcription$text <- corrected_transcription_text

# Convert the transcription segments to a data frame
transcription_segments <- transcription$segments
transcription_df <- data.frame(
  start = sapply(transcription_segments, function(x) x$start),
  end = sapply(transcription_segments, function(x) x$end),
  text = sapply(transcription_segments, function(x) x$text),
  speaker = "Speaker 1"  # Manually set to "Speaker 1" since there is only one speaker
)

# Save transcription to a text file
write(corrected_transcription_text, file = "C:/Users/16503/Documents/RSC/Practice/Audio_Transcription/transcription.txt")
```


```{r}
# Ensure the transcription text is split into multiple lines for more granularity
transcription_lines <- unlist(strsplit(transcription_text, split = "\\.\\s*"))

# Download and load a language model for English
ud_model <- udpipe_download_model(language = "english")
ud_model <- udpipe_load_model(ud_model$file_model)

# Annotate the transcription text using the udpipe model
annotated_transcription <- udpipe_annotate(ud_model, x = transcription_lines)
annotated_transcription <- as.data.frame(annotated_transcription)

# View the annotated transcription
head(annotated_transcription)
```

```{r}
# Convert the text into a tidy format
tidy_transcription <- tibble(line = seq_along(transcription_lines), text = transcription_lines) %>%
  unnest_tokens(word, text)

# View the tidy_transcription to ensure it has line and word columns
head(tidy_transcription)
```

```{r}
# Load sentiment lexicon
bing_sentiments <- get_sentiments("bing")

# Convert tidy_transcription and bing_sentiments to data frames
tidy_transcription_df <- as.data.frame(tidy_transcription)
bing_sentiments_df <- as.data.frame(bing_sentiments)

# Perform inner join using SQL
sentiment_join <- sqldf("
  SELECT t.line, t.word, s.sentiment
  FROM tidy_transcription_df AS t
  INNER JOIN bing_sentiments_df AS s
  ON t.word = s.word
")

# Inspect the sentiment_join table
head(sentiment_join)
summary(sentiment_join)

# Calculate sentiment score using SQL
sentiment_time <- sqldf("
  SELECT line, SUM(CASE WHEN sentiment = 'positive' THEN 1 ELSE -1 END) AS sentiment_score
  FROM sentiment_join
  GROUP BY line
")

# Check the distribution of sentiment scores
summary(sentiment_time)

# Plot sentiment over time
ggplot(sentiment_time, aes(x = line, y = sentiment_score)) +
  geom_line() +
  labs(title = 'Sentiment Over Time',
       x = 'Line',
       y = 'Sentiment Score')
```

```{r}
# Convert the text into a tidy format and remove stop words
tidy_transcription <- tibble(line = seq_along(transcription_lines), text = transcription_lines) %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words)

# Ensure no empty rows by grouping by line and summarizing
tidy_transcription <- tidy_transcription %>%
  group_by(line) %>%
  summarize(text = paste(word, collapse = " ")) %>%
  ungroup()

# Create a Corpus
corpus <- Corpus(VectorSource(tidy_transcription$text))

# Create a Document-Term Matrix
dtm <- DocumentTermMatrix(corpus, control = list(wordLengths = c(3, Inf)))

# Remove empty rows (documents with no terms)
rowTotals <- apply(dtm, 1, sum)
dtm <- dtm[rowTotals > 0,]

# Perform LDA for topic modeling
lda <- LDA(dtm, k = 5, control = list(seed = 1234))

# Extract the topics
topics <- tidy(lda, matrix = "beta")
top_terms <- topics %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

# Generate labels dynamically by concatenating top terms
generate_label <- function(terms) {
  paste(terms[1:3], collapse = ", ")
}

# Generate labels for each topic
topic_labels <- top_terms %>%
  group_by(topic) %>%
  summarise(label = generate_label(term)) %>%
  arrange(topic)

# Convert topic_labels to a named vector for labelling
topic_labels_vector <- setNames(topic_labels$label, topic_labels$topic)

# View the top terms in each topic
print(top_terms)
```

```{r}
# Interpret the topics
topic_labels <- c("Employment and Injuries", "Medical Examinations", "Time and Recovery", "Symptoms and Opinions", "Reports and History")

#This doesn't have to be hardcoded, but I couldn't quite figure it out

# Add topic labels to the plot
ggplot(top_terms, aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free", labeller = as_labeller(setNames(topic_labels, 1:5))) +
  coord_flip() +
  labs(title = "Top Terms in Each Topic",
       x = "Term",
       y = "Beta")
```

```{r}
# Visualize the top terms in each topic with dynamic labels
ggplot(top_terms, aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free", labeller = as_labeller(topic_labels_vector)) +
  coord_flip() +
  labs(title = "Top Terms in Each Topic",
       x = "Term",
       y = "Beta")
```

```{r}
plot_chroma <- function(chroma_df) {
  chroma_long <- chroma_df %>%
    tibble::rownames_to_column(var = "Row") %>%
    pivot_longer(cols = -Row, names_to = "Time", values_to = "Intensity")
  
  chroma_long$Time <- as.numeric(gsub("V", "", chroma_long$Time))
  chroma_long$Row <- as.factor(chroma_long$Row)
  
  ggplot(chroma_long, aes(x = Time, y = Row)) +
    geom_tile(aes(fill = Intensity)) +
    scale_fill_viridis_c() +
    labs(title = "Chroma Feature", x = "Time Frame", y = "Frequency Bin") +
    theme_minimal() +
    theme(
      plot.title = element_text(hjust = 0.5, size = 16),
      axis.title = element_text(size = 14),
      axis.text = element_text(size = 12),
      legend.title = element_text(size = 12),
      legend.text = element_text(size = 10)
    )
}

plot_tonnetz <- function(tonnetz_df) {
  tonnetz_long <- tonnetz_df %>%
    tibble::rownames_to_column(var = "Row") %>%
    pivot_longer(cols = -Row, names_to = "Time", values_to = "Value")
  
  tonnetz_long$Time <- as.numeric(gsub("V", "", tonnetz_long$Time))
  tonnetz_long$Row <- as.factor(tonnetz_long$Row)
  
  ggplot(tonnetz_long, aes(x = Time, y = Row)) +
    geom_tile(aes(fill = Value)) +
    scale_fill_viridis_c() +
    labs(title = "Tonnetz Feature", x = "Time Frame", y = "Tonnetz Dimension") +
    theme_minimal() +
    theme(
      plot.title = element_text(hjust = 0.5, size = 16),
      axis.title = element_text(size = 14),
      axis.text = element_text(size = 12),
      legend.title = element_text(size = 12),
      legend.text = element_text(size = 10)
    )
}

plot_waveform <- function(wave_df, title) {
  ggplot(wave_df, aes(x = time, y = amplitude)) +
    geom_line(linewidth = 1, color = "black") +  # Use black color for the waveform
    labs(title = title, x = "Time", y = "Amplitude") +
    theme_minimal() +
    theme(
      plot.title = element_text(hjust = 0.5, size = 16),
      axis.title = element_text(size = 14),
      axis.text = element_text(size = 12)
    )
}

# Example of using the updated plot functions
# Assuming `tonal_features` is a list containing your data frames for `chroma`, `tonnetz`, `harmony`, and `percussive`
plot_chroma(tonal_features$chroma)
plot_tonnetz(tonal_features$tonnetz)
plot_waveform(tonal_features$harmony, "Harmonic Component")
plot_waveform(tonal_features$percussive, "Percussive Component")
```


```{r}
write_csv(annotated_transcription, "C:/Users/16503/Documents/RSC/Practice/Audio_Transcription/annotated_transcription.csv")
write_csv(sentiment_time, "C:/Users/16503/Documents/RSC/Practice/Audio_Transcription/sentiment_time.csv")
write_csv(top_terms, "C:/Users/16503/Documents/RSC/Practice/Audio_Transcription/top_terms.csv")
write_csv(transcription_df, "C:/Users/16503/Documents/RSC/Practice/Audio_Transcription/transcription_with_timestamps_and_speakers.csv")
```
  
